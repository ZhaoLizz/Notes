# 数据预处理

## 一.数据集可能存在的问题
* 特征之间数据的规格不一样,(不属于同一量程).可以利用**无量纲化**解决
* 信息冗余:对于某些**定量特征**,包含的信息为区间划分.比如0-100的值表示一个区间,100-200的值表示一个区间,这样就会有信息的冗余.可以用**二值化**解决
* 定型特征不能直接使用:某些机器学习算法和模型只能接受定量特征的输入,那么需要将定性特征转化为定量特征.通常使用**哑编码**将定性特征转化为定量特征:
    * 假设有N中定性值,则将这一特征扩展为N中特征,当原始特征值为第i种定性值时,第i个扩展特征值赋值为1,其他扩展特征值赋值为0
* 存在缺失值
* 信息利用率低:不同的机器学习算法和模型对数据中的信息的利用率不同.

## 1. 无量纲化

### 标准化
![](https://ws1.sinaimg.cn/large/0077h8xtly1fqfw4w9exij304m02jdfm.jpg)


## 二.特征选择
数据预处理完成后,需要选择有意义的特征输入机器学习的算法和模型进行训练.通常从两个方面考虑来选择特征:
1. 特征是否发散:如果一个特征不发散,例如**方差**接近于0,也就是说样本在这个特征上基本没有差异,这个特征对样本的区分并没有什么用
2. 特征与目标的相关性:与目标相关性高的特征应该优先选择.

几种特征选择的方法:
* Filter过滤法:按照发散性或者相关性对各个特征进行评分,设定阈值或者待选择阈值的个数
    * 方差选择法
    * 相关系数法
    * 卡方检验
    * 互信息法
* Wrapper包装法:根据目标函数(通常是预测效果的评分)**,每次选择或者排除若干特征**
* Embedded嵌入法:先使用某些机器学习的算法和模型进行训练,得到各个特征的权值系数w_i,根据系数从大到小选择特征.通过训练来确定特征的优劣

### 1. 方差选择法
先计算各个特征的方差,然后根据阈值,选择方差大于阈值的特征
```python
from sklearn.feature_selection import VarianceThreshold
 
#方差选择法，返回值为特征选择后的数据
#参数threshold为方差的阈值
VarianceThreshold(threshold=3).fit_transform(iris.data)
```

### 2. 相关系数法
使用相关系数法,计算各个特征对目标值的相关系数以及相关系数的P值

```python

```

### 3. 卡方检验
检验**定性自变量对定性因变量的相关性**:假设自变量有N种取值,因变量有M种取值,考虑自变量等于i且因变量等于j的样本频数的观察值与期望的差距

$x^2 = \sum \frac {(A-E)^2} {E}$

```python
1 from sklearn.feature_selection import SelectKBest
2 from sklearn.feature_selection import chi2
3 
4 #选择K个最好的特征，返回选择特征后的数据
5 SelectKBest(chi2, k=2).fit_transform(iris.data, iris.target)
```

### 4. 互信息法


### 5. Wrapper递归特征消除法
递归消除特征法使用一个基模型来进行多轮训练,每轮训练后消除若干权值系数的特征,再基于新的特征集进行下一轮训练

```python
1 from sklearn.feature_selection import RFE
2 from sklearn.linear_model import LogisticRegression
3 
4 #递归特征消除法，返回特征选择后的数据
5 #参数estimator为基模型
6 #参数n_features_to_select为选择的特征个数
7 RFE(estimator=LogisticRegression(), n_features_to_select=2).fit_transform(iris.data, iris.target)
```

### 6. Embedded
####　ａ．基于惩罚项的特征选择法
使用待惩罚项的基模型，除了筛选出特征外，同时也进行了降维．使用`feature_selection`库的SelectFromModel类结合带L
惩罚项的逻辑回归模型:
```python
1 from sklearn.feature_selection import SelectFromModel
2 from sklearn.linear_model import LogisticRegression
3 
4 #带L1惩罚项的逻辑回归作为基模型的特征选择
5 SelectFromModel(LogisticRegression(penalty="l1", C=0.1)).fit_transform(iris.data, iris.target)
```

